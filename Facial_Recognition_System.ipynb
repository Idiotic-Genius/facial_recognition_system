{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT NOTE**: Please edit the paths according to your needs."
      ],
      "metadata": {
        "id": "XXY8lq89olzo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBvSe8u2O2fN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Testing dataset directory which includes the labels.txt file in it\n",
        "test_data_path = \"/content/drive/MyDrive/test\"\n",
        "\n",
        "# Training dataset directory path\n",
        "# ***IMPORTANT***: The one with all the people's names as the sub-directories\n",
        "training_data_path = \"/content/drive/MyDrive/Release\"\n",
        "\n",
        "# Saved models directory path\n",
        "saved_models_dir = \"/content/drive/MyDrive/saved_models\"\n",
        "\n",
        "# Location of face detection DNN pre-trained model files\n",
        "# dnn_prototxt_path = \"/content/drive/MyDrive/pre_trained_files/deploy.prototxt\"\n",
        "# dnn_model_path = \"/content/drive/MyDrive/pre_trained_files/res10_300x300_ssd_iter_140000.caffemodel\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions"
      ],
      "metadata": {
        "id": "1il1wmIR4EhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "4FkgWFEnXpvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dria8izcT6ah"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from typing import Tuple, Optional, List\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "!pip3 install pillow-heif\n",
        "from pillow_heif import register_heif_opener\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import distance_metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "!pip3 install joblib\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "VNxU0Wi1YdxR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUHdm0_Izi3R"
      },
      "outputs": [],
      "source": [
        "def augment_image(\n",
        "    image: np.ndarray,\n",
        "    num_augs: int = 5\n",
        ") -> List[np.ndarray]:\n",
        "    \"\"\"Generates and returns a number of augmented images plus the orginal\"\"\"\n",
        "    # Initialize parameter ranges for augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Store the augmented images, including the original image\n",
        "    aug_images = [image]\n",
        "\n",
        "    image = image.reshape((1,) + image.shape)\n",
        "    # Apply of the data augmentation on the image\n",
        "    for i, batch in enumerate(datagen.flow(image, batch_size=1)):\n",
        "        aug_image = batch[0].astype('uint8')\n",
        "        aug_images.append(aug_image)\n",
        "\n",
        "        # Break after generating the specified number of augmentations\n",
        "        if i == num_augs - 1:\n",
        "            break\n",
        "\n",
        "    return aug_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rKBysjV4m8"
      },
      "source": [
        "Face detection and cropping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DdiMY8XWcKx"
      },
      "outputs": [],
      "source": [
        "def get_face_from_image_fc(\n",
        "    input_image: np.ndarray,\n",
        "    face_cascade: Optional[cv2.CascadeClassifier] = None\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Detects and crops and image of a face\"\"\"\n",
        "    # Convert image to gray scale to reduce affects from other factors\n",
        "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "    # Histogram equalization\n",
        "    gray_image = cv2.equalizeHist(gray_image)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    if face_cascade is None:\n",
        "        face_cascade = cv2.CascadeClassifier(\n",
        "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "    )\n",
        "    faces = face_cascade.detectMultiScale(\n",
        "        gray_image,\n",
        "        scaleFactor=1.03,\n",
        "        minNeighbors=5,\n",
        "        minSize=(30, 30)\n",
        "    )\n",
        "\n",
        "    # No faces are detected\n",
        "    if len(faces) == 0:\n",
        "        print(\"No faces detected in the image. Returning original image.\")\n",
        "        return input_image\n",
        "\n",
        "    if len(faces)>1:\n",
        "        print('Multiple faces detected. Returning first face detected.')\n",
        "        # print('Extra face boundaries: ', faces[1:])\n",
        "\n",
        "    # Get the coordinates of the first face detected\n",
        "    x, y, w, h = faces[0]\n",
        "\n",
        "    # Crop the image to center it on the face detected\n",
        "    cropped_image = input_image[y:y+h, x:x+w]\n",
        "\n",
        "    # Return cropped image\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def get_face_from_image_dnn(\n",
        "    input_image: np.ndarray,\n",
        "    prototxt_path: str,\n",
        "    model_path: str,\n",
        "    confidence_threshold: float = 0.15,\n",
        "    relative_change_threshold: float = 0.3\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Detects and crops an image of a face using a dnn model.\"\"\"\n",
        "\n",
        "    # Load the pre-trained dnn model\n",
        "    net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
        "\n",
        "    # Prepare the image for face detection\n",
        "    blob = cv2.dnn.blobFromImage(\n",
        "        image=cv2.resize(input_image, (300, 300)),\n",
        "        scalefactor=1.0,\n",
        "        size=(300, 300),\n",
        "        mean=(104.0, 177.0, 123.0)\n",
        "    )\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Run the forward pass to get face detections\n",
        "    detections = net.forward()\n",
        "\n",
        "    # Sort detections based on confidence (descending order)\n",
        "    sorted_detections = sorted(\n",
        "        range(detections.shape[2]),\n",
        "        key=lambda i: detections[0, 0, i, 2],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    # Get most confident face and crop using its bounding box\n",
        "    most_confident = detections[0, 0, sorted_detections[0], 2]\n",
        "    if most_confident >= confidence_threshold:\n",
        "        box = detections[0, 0, sorted_detections[0], 3:7] * np.array(\n",
        "            [input_image.shape[1],\n",
        "             input_image.shape[0],\n",
        "             input_image.shape[1],\n",
        "             input_image.shape[0]])\n",
        "        (x, y, w, h) = box.astype(\"int\")\n",
        "\n",
        "        # Draw the bounding box on the original image\n",
        "        # cv2.rectangle(input_image, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
        "        # cv2_imshow(input_image)\n",
        "\n",
        "        # Crop the image to center it on the face detected\n",
        "        cropped_image = input_image[y:y+h, x:x+w]\n",
        "\n",
        "        # Return image based on relative change (size) of input_image size\n",
        "        relative_change_size = abs((cropped_image.size-input_image.size) / input_image.size)\n",
        "        if relative_change_size <= relative_change_threshold:\n",
        "            return cropped_image\n",
        "\n",
        "    else:\n",
        "        # No faces detected\n",
        "        print(\"No faces detected in the image. Returning original image.\")\n",
        "        return input_image\n",
        "\n",
        "    # Keep recursing until relative change (size) conditions are met\n",
        "    return get_face_from_image_dnn(cropped_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM_aCfv2zNls"
      },
      "source": [
        "Split dataset for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e__TbzjEkG-6"
      },
      "outputs": [],
      "source": [
        "def get_data_and_label(input_dir: str) -> Tuple[np.ndarray, List[str]]:\n",
        "    \"\"\"Iterate through input directory and get the images and labels\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img in pathlib.Path(input_dir).iterdir():\n",
        "        # Read the image and label\n",
        "        image = cv2.imread(str(img))\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = image.flatten()\n",
        "        images.append(image)\n",
        "        name = img.stem.split('_')[0]\n",
        "        labels.append(name)\n",
        "    images_arr = np.array(images)\n",
        "\n",
        "    return images_arr, labels\n",
        "\n",
        "\n",
        "def group_files_by_name(file_names: List[str]) -> dict:\n",
        "    grouped_files = {}\n",
        "    for file_name in file_names:\n",
        "        base_name, _ = str(file_name).rsplit('_', 1)\n",
        "        if base_name in grouped_files:\n",
        "            grouped_files[base_name].append(file_name)\n",
        "        else:\n",
        "            grouped_files[base_name] = [file_name]\n",
        "\n",
        "    return grouped_files\n",
        "\n",
        "\n",
        "def split_images_train_and_val(\n",
        "    source_dir: str,\n",
        "    output_dir: str,\n",
        "    split_ratio: float = 0.8\n",
        ") -> None:\n",
        "    # Ensure the source directory exists\n",
        "    # source_path = pathlib.Path(source_dir)\n",
        "    if not source_dir.is_dir():\n",
        "        raise FileNotFoundError(f\"Source directory '{source_dir}' not found.\")\n",
        "\n",
        "    # Create train and validation directories within the source directory\n",
        "    # output_path = pathlib.Path(output_dir)\n",
        "    if output_dir.is_dir():\n",
        "        print(f\"{output_dir} output directory exist already, doing nothing.\")\n",
        "        return\n",
        "    output_dir.mkdir(exist_ok=False)\n",
        "    train_path = output_dir.joinpath('train')\n",
        "    val_path = output_dir.joinpath('validation')\n",
        "    train_path.mkdir(exist_ok=True)\n",
        "    val_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Get a list of all image files (should all be .png format)\n",
        "    image_files = list(source_dir.glob('*.png'))\n",
        "\n",
        "    # Create a dict to group all the images based on label\n",
        "    grouped_image_files = group_files_by_name(image_files)\n",
        "\n",
        "    # For each class, split the images into training and validation\n",
        "    for base_name, files in grouped_image_files.items():\n",
        "        # Randomly split the images\n",
        "        num_train = int(len(files) * split_ratio)\n",
        "        random.shuffle(files)\n",
        "        train_set = files[:num_train]\n",
        "        val_set = files[num_train:]\n",
        "\n",
        "        # Move images to the corresponding directories\n",
        "        for img_file in train_set:\n",
        "            shutil.copy(str(img_file), str(train_path / img_file.name))\n",
        "        for img_file in val_set:\n",
        "            shutil.copy(str(img_file), str(val_path / img_file.name))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhcW9X0-ZHy"
      },
      "source": [
        "Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTH7n6v0-ZSu"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(\n",
        "    input_dir_path: str,\n",
        "    output_dir_path: str,\n",
        "    face_detection_method: str = 'fc'\n",
        ") -> None:\n",
        "    \"\"\"Preprocess all the images in a directory\"\"\"\n",
        "    # Check if the provided face detection method is valid\n",
        "    valid_fd_methods = [\"dnn\", \"fc\"]\n",
        "    if face_detection_method not in valid_fd_methods:\n",
        "        raise ValueError(f\"Invalid face_detection_method. Choose from {valid_fd_methods}\")\n",
        "    print(f\"Using: {face_detection_method} as the face_detection_method.\")\n",
        "\n",
        "    # Output directory path\n",
        "    output_dir = pathlib.Path(output_dir_path)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Iterate through all of images in the input directory\n",
        "    for img in pathlib.Path(input_dir_path).iterdir():\n",
        "        image = cv2.imread(str(img))\n",
        "        output_file = output_dir.joinpath(img.name)\n",
        "        if output_file.is_file():\n",
        "            print(f\"File={output_file} already exist, skipping.\")\n",
        "            continue\n",
        "        print(f\"input image: {img}\")\n",
        "\n",
        "        # Apply data augmentation\n",
        "        augmented_images = augment_image(np.array(image))\n",
        "\n",
        "        for idx, a_img in enumerate(augmented_images):\n",
        "            # Detect face and crop image\n",
        "            # Use dnn model\n",
        "            if face_detection_method == 'dnn':\n",
        "                cropped_image = get_face_from_image_dnn(\n",
        "                    input_image=a_img,\n",
        "                    prototxt_path=dnn_prototxt_path,\n",
        "                    model_path=dnn_model_path\n",
        "                )\n",
        "            # Use face_cascade\n",
        "            if face_detection_method == 'fc':\n",
        "                face_cascade = cv2.CascadeClassifier(\n",
        "                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "                )\n",
        "                cropped_image = get_face_from_image_fc(\n",
        "                    input_image=a_img,\n",
        "                    face_cascade=face_cascade\n",
        "                )\n",
        "\n",
        "            # Normalize the cropped image\n",
        "            image_norm = cv2.resize(cropped_image, (224, 224))\n",
        "\n",
        "            # Save images\n",
        "            new_filename = f\"{output_file.stem}{idx}{output_file.suffix}\"\n",
        "            new_file = output_dir.joinpath(new_filename)\n",
        "            cv2.imwrite(str(new_file), image_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename and Normalize test file to work with our labelling system"
      ],
      "metadata": {
        "id": "T50yvMqpfdAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_png(input_path, output_path):\n",
        "    try:\n",
        "        with Image.open(input_path) as img:\n",
        "            img.save(output_path, 'PNG')\n",
        "        print(f\"Converted {input_path} to {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting {input_path}: {e}\")\n",
        "\n",
        "\n",
        "def batch_convert_to_png(input_dir, output_dir):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    output_path = pathlib.Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Loop through all files in the input directory\n",
        "    input_path = pathlib.Path(input_dir)\n",
        "    for file_path in input_path.iterdir():\n",
        "        # Check if the file is a file but not the labels.txt file\n",
        "        if file_path.is_file() and file_path.suffix != '.txt':\n",
        "            output_filename = file_path.stem + \".png\"\n",
        "            output_file_path = output_path.joinpath(output_filename)\n",
        "            convert_to_png(file_path, output_file_path)\n",
        "\n",
        "\n",
        "def generate_new_filenames(input_text):\n",
        "    \"\"\"Create a mapping of old names to new names\"\"\"\n",
        "    name_mapping = {}\n",
        "    counters = defaultdict(int)\n",
        "\n",
        "    lines = input_text.strip().split('\\n')\n",
        "\n",
        "    for line in lines:\n",
        "        filename, name = line.split('\\t')\n",
        "        counter = counters[name]\n",
        "        counters[name] += 1\n",
        "        new_filename = f\"{name}_{counter}.png\"\n",
        "        name_mapping[filename] = new_filename\n",
        "\n",
        "    return name_mapping\n",
        "\n",
        "\n",
        "def normalize_test_files(\n",
        "    labels_file_path: str,\n",
        "    image_dir: str,\n",
        "    output_dir: str\n",
        ") -> None:\n",
        "    \"\"\"Renames and copies the files from the testing dataset to our labelling system\"\"\"\n",
        "    batch_convert_to_png(image_dir, image_dir)\n",
        "\n",
        "    with open(labels_file_path, 'r') as file:\n",
        "        input_text = file.read()\n",
        "    name_mapping = generate_new_filenames(input_text)\n",
        "\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    for old_name, new_name in name_mapping.items():\n",
        "        # Rename the file and copy to new location\n",
        "        old_file_path = image_dir.joinpath(old_name)\n",
        "        if not old_file_path.exists():\n",
        "            continue\n",
        "        new_file_path = output_dir.joinpath(new_name)\n",
        "        shutil.copy(old_file_path, new_file_path)"
      ],
      "metadata": {
        "id": "STFIk5rcfocp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the file types and labelling"
      ],
      "metadata": {
        "id": "hWkkQ4t2ZFPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flattenData(\n",
        "    ipath,\n",
        "    opath,\n",
        "    nameOverride=None,\n",
        "    indexInit=0\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Takes all files under ipath, or the file at ipath (default under\n",
        "    Training/Release), and outputs the same files as name_i.png all directly\n",
        "    under opath (default under Training/Flattened), with name set to the name\n",
        "    of the subdirectory directly above the input file (by default) and i being a\n",
        "    zero-based (by default) index of that specific subdirectory.\n",
        "    \"\"\"\n",
        "    register_heif_opener()\n",
        "    rdf=list(os.walk(ipath))\n",
        "    if not rdf:\n",
        "        rdf=('/'.join(ipath.split('/')[:-1]),[],[ipath.split('/')[-1]])\n",
        "    for root,dirs,files in rdf:\n",
        "        person=nameOverride\n",
        "        for f in files:\n",
        "            if person!=root.split('/')[-1]:\n",
        "                if not nameOverride:\n",
        "                    person=root.split('/')[-1]\n",
        "                index=indexInit\n",
        "            with Image.open(os.path.join(root,f)) as im:\n",
        "                im.save(os.path.join(opath,'_'.join([person,str(index)])+'.png'))\n",
        "            index+=1"
      ],
      "metadata": {
        "id": "MK2CmUjRZG0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and validating classifers"
      ],
      "metadata": {
        "id": "11pFRkfUY1no"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MuD9h2DaIOc"
      },
      "outputs": [],
      "source": [
        "def train_classifier(X_train, X_test, y_train, y_test, clf, clf_name, param_grid):\n",
        "    \"\"\"Train and test a classifier\"\"\"\n",
        "    pca = PCA()\n",
        "    scaler = StandardScaler()\n",
        "    pipe = Pipeline(steps=[(\"scaler\", scaler), (\"dim_reduction\", pca), (\"clf\", clf)])\n",
        "\n",
        "    # Set to find best dimensionality reduction method\n",
        "    param_grid[\"dim_reduction__n_components\"] = [5, 10, 25, 50]\n",
        "\n",
        "    # Find best params\n",
        "    search = GridSearchCV(pipe, param_grid, scoring='f1_weighted')\n",
        "    search.fit(X_train, y_train)\n",
        "    print(\"CV score=%0.3f with parameters:\" % search.best_score_)\n",
        "    print(search.best_params_)\n",
        "\n",
        "    # Use the best parameters for the classifier\n",
        "    best_params = search.best_params_\n",
        "    pca.set_params(n_components=best_params[\"dim_reduction__n_components\"])\n",
        "    clf_best_params = {key.replace(\"clf__\", \"\"): value for key, value in best_params.items() if \"clf__\" in key}\n",
        "    clf.set_params(**clf_best_params)\n",
        "    clf_pipe = Pipeline(steps=[(\"scaler\", scaler), (\"dim_reduction\", pca), (\"clf\", clf)])\n",
        "\n",
        "    # Train\n",
        "    clf_pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    train_predictions = clf_pipe.predict(X_train)\n",
        "    test_predictions = clf_pipe.predict(X_test)\n",
        "\n",
        "    # Evaluate the accuracy\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    validation_accuracy = accuracy_score(y_test, test_predictions)\n",
        "    print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "    print(f\"Validation Accuracy: {validation_accuracy:.2f}\")\n",
        "\n",
        "    # Save the classifer (WARNING: This will override previously saved models)\n",
        "    model_name = clf_name + \"_clf.pkl\"\n",
        "    model_save_path = pathlib.Path(saved_models_dir).joinpath(model_name)\n",
        "    joblib.dump(clf_pipe, model_save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and Training"
      ],
      "metadata": {
        "id": "prc-xMEQdhKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establish paths for datasets"
      ],
      "metadata": {
        "id": "PtfPCmWEW8hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source directory after normalizing file types and established labelling\n",
        "source_dir = pathlib.Path(training_data_path).joinpath('Flattened')\n",
        "\n",
        "# Ratio for spliting dataset between training and validation\n",
        "split_ratio = 0.8\n",
        "\n",
        "# Preprocessed dataset path\n",
        "preprocessed_dir = pathlib.Path(training_data_path).joinpath(f\"Preprocessed_Split_{split_ratio}\")\n",
        "\n",
        "# Training set paths\n",
        "training_path = preprocessed_dir.joinpath(\"train\")\n",
        "output_train_path = preprocessed_dir.joinpath(training_path.stem + \"_preprocessed\")\n",
        "\n",
        "# Validation set paths\n",
        "validation_path = preprocessed_dir.joinpath(\"validation\")\n",
        "output_val_path = preprocessed_dir.joinpath(validation_path.stem + \"_preprocessed\")\n",
        "\n",
        "# Create a save_models_dir if one doesn't already exist\n",
        "pathlib.Path(saved_models_dir).mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "vmfbGI2pRh71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize raw dataset file type and labelling system"
      ],
      "metadata": {
        "id": "kR1gS7xcXDc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir.mkdir(exist_ok=True)\n",
        "flattenData(\n",
        "    ipath=training_data_path,\n",
        "    opath=source_dir\n",
        ")"
      ],
      "metadata": {
        "id": "11YLQy4TXDSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create training and validation sets"
      ],
      "metadata": {
        "id": "lOJQ4dhuZWBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into a training and validation set\n",
        "split_images_train_and_val(\n",
        "    source_dir=source_dir,\n",
        "    output_dir=preprocessed_dir,\n",
        "    split_ratio=split_ratio\n",
        ")\n",
        "\n",
        "# Preprocess the datasets\n",
        "# Training set\n",
        "preprocess_dataset(\n",
        "    input_dir_path=training_path,\n",
        "    output_dir_path=output_train_path\n",
        ")\n",
        "# Validation set\n",
        "preprocess_dataset(\n",
        "    input_dir_path=validation_path,\n",
        "    output_dir_path=output_val_path\n",
        ")\n",
        "\n",
        "# NOTE: should manually clean up any poor quality images"
      ],
      "metadata": {
        "id": "1IcIdj83O9IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the training and validation data and labels\n",
        "X_train, y_train = get_data_and_label(\n",
        "    input_dir=output_train_path\n",
        ")\n",
        "X_val, y_val = get_data_and_label(\n",
        "    input_dir=output_val_path\n",
        ")"
      ],
      "metadata": {
        "id": "3o4dvkscRNnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train, validate, and tune hyperparameters"
      ],
      "metadata": {
        "id": "he36HDU_Z9XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the classifers\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "rf_grid = {\n",
        "    \"clf__n_estimators\": [50, 75, 125],\n",
        "    \"clf__max_depth\": [4, 8, 12],\n",
        "}\n",
        "rf_clf = RandomForestClassifier(random_state=22)\n",
        "train_classifier(X_train, X_val, y_train, y_val, rf_clf, 'rf', rf_grid)\n",
        "print(\"---\")\n",
        "\n",
        "print(f\"KNN:\")\n",
        "knn_grid = {\n",
        "    \"clf__n_neighbors\": [3, 5, 7],\n",
        "}\n",
        "knn_clf = KNeighborsClassifier()\n",
        "train_classifier(X_train, X_val, y_train, y_val, knn_clf, 'knn', knn_grid)\n",
        "print(\"---\")\n",
        "\n",
        "print(\"SVM:\")\n",
        "svm_grid = {\n",
        "    \"clf__C\": [1, 2, 4],\n",
        "    \"clf__gamma\": [1/8, 1/16, 1/32],\n",
        "}\n",
        "svm_clf = SVC(kernel='rbf')\n",
        "train_classifier(X_train, X_val, y_train, y_val, svm_clf, 'svm', svm_grid)\n",
        "print(\"---\")"
      ],
      "metadata": {
        "id": "Asg8FDHGfT58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "nLLjMDP15ssu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing dataset directory which includes the labels.txt file in it\n",
        "test_dir_path = pathlib.Path(test_data_path)\n",
        "\n",
        "# Path to desired output the normalized and flattened testing dataset\n",
        "output_test_path = test_dir_path.joinpath(\"Flattened\")"
      ],
      "metadata": {
        "id": "L5C5Qn70o0-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the file types and labelling\n",
        "normalize_test_files(\n",
        "    labels_file_path=test_dir_path.joinpath('labels.txt'),\n",
        "    image_dir=test_dir_path,\n",
        "    output_dir=output_test_path\n",
        ")\n",
        "\n",
        "# Face detection and cropping\n",
        "for image in output_test_path.iterdir():\n",
        "    img = cv2.imread(str(image))\n",
        "    cropped_image = get_face_from_image_dnn(input_image=img)\n",
        "\n",
        "    # Normalize the cropped image\n",
        "    image_norm = cv2.resize(cropped_image, (224, 224))\n",
        "\n",
        "    # Save images\n",
        "    cv2.imwrite(str(image), image_norm)\n"
      ],
      "metadata": {
        "id": "HIgQ2KDS7cvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data and labels\n",
        "X_test, y_test = get_data_and_label(\n",
        "    input_dir=output_test_path\n",
        ")"
      ],
      "metadata": {
        "id": "IowBtn_k7emv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the specific trained model you want to test\n",
        "trained_clf = \"/content/drive/MyDrive/saved_models/svm_clf.pkl\"\n",
        "trained_clf_path = pathlib.Path(trained_clf)\n",
        "\n",
        "clf = joblib.load(trained_clf)\n",
        "test_predictions = clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"Test Accuracy for {trained_clf_path.stem}: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "WWyr-fsf5wPB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "prc-xMEQdhKq",
        "nLLjMDP15ssu"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}